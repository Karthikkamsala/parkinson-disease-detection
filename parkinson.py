# -*- coding: utf-8 -*-
"""parkinson.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hG_82VwrRe9KMIM0BXSk2-kZlfVevcrb
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

pk_data= pd.read_csv('/content/parkinson.csv')

pk_data.head()

pk_data.info()

"""# no null values in any of the coloumn

"""

pk_data.shape

pk_data.isnull().sum()  # sum() will gives only the null value count

pk_data.describe()

pk_data['status'].value_counts() # checking how many are affected with parkinson 1= affected 0= not affected

# grouping all the attributes based on status with using the mean values 
pk_data.groupby('status').mean()

x= pk_data.drop(columns=['name','status'], axis=1)   #for coloumns axis=1 , for rows axis=0
y=pk_data['status']

print(x)

print(y)

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=3)
# splitting into train and test data
#test_size=0.2 is 20% of data will be assigned for testing
#random_state is for selecting the data in random facshion

print(x.shape,x_train.shape,x_test.shape) #checking the split

#data standardisation 
''' data has very large values so we need to change it into normal form without changing the meaing '''
scaler =StandardScaler()

scaler.fit(x_train)

x_train=scaler.transform(x_train)
x_test=scaler.transform(x_test)

x_train

#training the model using SVM
model=svm.SVC(kernel='linear')

model.fit(x_train,y_train)

x_train_predict =model.predict(x_train)
train_accuracy=accuracy_score(y_train,x_train_predict)
print(train_accuracy)

x_test_predict=model.predict(x_test)
test_accuracy=accuracy_score(y_test,x_test_predict)
print(test_accuracy)

#building the model
input_data=(136.926,159.866,131.276,0.00293,0.00002,0.00118,0.00153,0.00355,0.01259,0.112,0.00656,0.00717,0.0114,0.01968,0.00581,25.703,0.4606,0.646846,-6.547148,0.152813,2.041277,0.138512)
numpy_array=np.asarray(input_data)
reshaped_data=numpy_array.reshape(1,-1)
standard_data=scaler.transform(reshaped_data)
prediction=model.predict(standard_data)
print(prediction)
if(prediction == 1):
  print("affected by parkinson ")
  
else:
  print("not affected by parkinson")

